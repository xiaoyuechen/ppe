\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{listings}

\title{Lab 2}
\author{Hannah Atmer and Xiaoyue Chen \\ Team 6}
\date{October 2021}

\begin{document}

\maketitle

\section{Performance Estimates}

\begin{figure}[h!t]
    \centering
    \includegraphics[width=1\textwidth]{predicted.png}
    \caption{Predicted Performance Impact}
    \label{fig:predicted}
\end{figure}

\section{Performance Achieved}

\subsection{Your measured performance results from implementing the optimizations.}

\begin{figure}[h!t]
    \centering
    \includegraphics[width=1\textwidth]{actual.png}
    \caption{Actual Performance Impact}
    \label{fig:actual}
\end{figure}

\subsection{The parallel scaling of your implementation.}

\begin{figure}[h!t]
    \centering
    \includegraphics[width=1\textwidth]{parallel.png}
    \caption{Parallel Scaling}
    \label{fig:parallel}
\end{figure}

\section{Discussion}

\subsection{A discussion of the measured results and how they differ
  from your predictions.}
We expected the kernel execution would be 50 times faster than the CPU
version. The measured results show that the actual speedup is around
14 times. The overhead might come from calling OpenCL api calls.

We expected the data movement would be the major bottleneck. The
measured results show that it is indeed the case. The data movement
time is even longer than we expected. Around 300 ms is spent on
data movement while only 7 ms was spent on the kernel execution.

\subsection{A discussion of what you learned about these optimizations from implementing them and measuring the results.}

\subsection{Comment on any unexpected or odd results.}

\subsection{Comments on the difficulty of the GPU offload.}

\section{Lab comments}
Any feedback on the lab itself.

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
